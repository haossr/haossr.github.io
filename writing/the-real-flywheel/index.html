---
layout: null
---
<!DOCTYPE html>
<html lang="en">

<head>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-R7BNJ90QEW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);} 
    gtag('js', new Date());
    gtag('config', 'G-R7BNJ90QEW');
  </script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>The Real Flywheel | {{ site.title }}</title>
  <meta name="description" content="A note on why the key bottleneck in frontier AI is effective datapoint throughput, and why agent-accelerated infra is the real flywheel.">
  <link rel="shortcut icon" href="{{ site.favicon }}" type="image/vnd.microsoft.icon">
  <link rel="stylesheet" href="/assets/css/styles.css">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  <style>
    .essay-page { background: #f8f9fb; min-height: 100vh; padding: 40px 16px; }
    .essay-wrap { max-width: 980px; margin: 0 auto; }
    .essay-card {
      background: #fff;
      border: 1px solid #e5e7eb;
      border-radius: 12px;
      box-shadow: 0 12px 30px rgba(0, 0, 0, 0.06);
      padding: 28px;
    }
    .essay-top { display: flex; justify-content: space-between; align-items: baseline; gap: 12px; margin-bottom: 14px; }
    .essay-title { margin: 0; font-size: 38px; line-height: 1.18; color: #111827; text-align: left; }
    .essay-meta { color: #6b7280; font-size: 14px; }
    .essay-content h2, .essay-content h3, .essay-content h4 { display: block; margin: 30px 0 12px; color: #111827; }
    .essay-content h2 { font-size: 28px; font-weight: 700; }
    .essay-content h3 { font-size: 22px; font-weight: 700; }
    .essay-content h4 { font-size: 19px; font-weight: 700; }
    .essay-content p { margin: 0 0 18px; color: #1f2937; font-size: 20px; line-height: 1.82; letter-spacing: 0.005em; }
    .essay-content ul, .essay-content ol { margin: 0 0 18px 24px; }
    .essay-content li { margin-bottom: 10px; color: #1f2937; font-size: 19px; line-height: 1.72; }
    .essay-content blockquote {
      margin: 14px 0 20px;
      padding: 12px 16px;
      border-left: 3px solid #07889b;
      background: #f7fbfc;
      color: #0f172a;
      font-size: 19px;
      line-height: 1.7;
      font-style: italic;
    }
    .inline-math {
      font-family: "SFMono-Regular", Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.9em;
      background: #f3f4f6;
      border: 1px solid #e5e7eb;
      border-radius: 6px;
      padding: 1px 6px;
      white-space: nowrap;
    }
    .appendix {
      margin-top: 28px;
      border: 1px solid #dbe4ff;
      border-radius: 10px;
      background: #f8faff;
      padding: 10px 14px 14px;
    }
    .appendix > summary {
      cursor: pointer;
      color: #1e3a8a;
      font-size: 18px;
      font-weight: 700;
      margin: 2px 0 8px;
      list-style-position: outside;
    }
    .appendix .equation-line {
      margin: 12px 0 18px;
      padding: 10px 12px;
      border-left: 3px solid #93c5fd;
      background: #eff6ff;
      font-family: "SFMono-Regular", Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 16px;
      line-height: 1.6;
      color: #0f172a;
      overflow-x: auto;
    }
    @media (max-width: 900px) {
      .essay-wrap { max-width: 860px; }
      .essay-title { font-size: 34px; }
      .essay-content p { font-size: 18px; line-height: 1.72; }
      .essay-content li { font-size: 17px; line-height: 1.65; }
      .essay-content blockquote { font-size: 17px; line-height: 1.62; }
      .appendix > summary { font-size: 17px; }
      .appendix .equation-line { font-size: 14px; }
    }
    @media (max-width: 600px) {
      .essay-card { padding: 20px; }
      .essay-title { font-size: 28px; }
      .essay-top { flex-direction: column; align-items: flex-start; }
      .essay-content p { font-size: 17px; line-height: 1.65; }
      .essay-content li, .essay-content blockquote { font-size: 16px; line-height: 1.55; }
    }
  </style>
</head>

<body class="essay-page">
  <div class="essay-wrap">
    <article class="essay-card essay-content">
      <div class="essay-top">
        <a class="reading-back" href="/">&larr; Back home</a>
        <div class="essay-meta">Feb 7, 2026</div>
      </div>

      <h1 class="essay-title">The Real Flywheel</h1>
      <p><strong>TL;DR:</strong> A flywheel that needs humans to spin it is a treadmill. A coding agent is not.</p>

      <p>Almost a year ago, right after my post-training team shipped several major GPT‑4o updates, I felt exhausted — excited, but oddly disoriented.</p>
      <p>This was March 2025. DAU looked great. The holdout set showed a 6%+ lift. In any normal product org, that’s champagne.</p>
      <p>And we had, in a sense, found what search / recommendation / ads people have always treated as the holy grail: a large user base; a plausible story for turning behavior into training signal; and a crew of MLEs who could stack endless small wins until the metrics moved.</p>
      <p>But it still wasn’t AGI. It was the old comfortable paradigm. The wins didn’t compound into a capability jump; the curve could flatten at any moment.</p>
      <p>It felt like raising a <a href="https://en.wikipedia.org/wiki/The_Lifecycle_of_Software_Objects"><em>digient in The Lifecycle of Software Objects</em></a> — they keep getting better, but they don’t grow up.</p>
      <p>That realization drained me. I started looking for a different kind of work.</p>
      <p>This post is what I found over the next 12 months — and the prediction it left me with.</p>

      <h3>Some Flywheels</h3>
      <p>In search / recs / ads, the canonical flywheel is: you ship, users show up, behavior becomes signal, the model improves, and you ship again.</p>
      <p>At scale, the user base is not only the prize — it’s inertia. Data stops feeling like fuel and starts acting like stored momentum: you bank it, and you spend it to move faster.</p>
      <p>Autonomous driving was the same story with different nouns: miles become edge cases; edge cases become autonomy; autonomy buys more miles.</p>

      <h3>The Real Flywheel</h3>
      <p>A flywheel that needs humans to spin it is a treadmill.</p>
      <p>With humans in the loop, iteration speed is capped by meetings, reviews, coordination, and the tiny number of changes you can safely push at once.</p>
      <p>A/B testing is the slowest version of this: you burn millions of interactions to buy one decision. Even “better” loops — CTR/CVR models, implicit feedback training — are still downstream of UI exposure and confounders. The signal is real, but it’s shaped by humans at every step.</p>
      <p>The real question is stricter:</p>
      <blockquote>Can we turn ideas into clean, attributable evidence on demand — repeatedly — without a human ceremony layer each time?</blockquote>
      <p>If you’ve used Codex / Claude Code seriously, you can feel the first crack in the treadmill. Once enough engineers believe agents are real, the loop starts closing on itself.</p>

      <h3>Data Point and Researcher</h3>
      <p>My mental model is blunt: if you have enough experimental datapoints, even an okay researcher will find the manifold.</p>
      <p>With 10× more datapoints, an average PhD can look like Ilya.</p>
      <p>With 10^5× more datapoints, a strong agent can start to look like a serious researcher.</p>
      <p>Not because theory stops mattering, but because a lot of frontier work sits uncomfortably close to the empirical end of the spectrum: you learn by trying.</p>
      <p>And a “datapoint” here is not a single training example. It’s an end-to-end belief update produced by a long rollout of humans, GPUs, and org structure — from data center capacity to an experiment proposal, data plumbing, training runs, babysitting failures, and writing the Slack post.</p>
      <p>A clean ablation. A failure with a named failure mode and a concrete fix. A new eval slice that exposes a blind spot. An online signal you can trace back to a capability.</p>
      <p>I don’t buy that idea supply is the bottleneck in frontier labs. GPU supply isn’t either — money can buy more GPUs (and hire brains).</p>
      <p>The bottleneck is how fast you can convert an idea into a high‑signal datapoint — and then do it again.</p>
      <p>When people say “AI improves itself,” the first thing that happens is probably not AI proposing one brilliant idea that reshapes the landscape. It’s a boring multiplier: more attempts per unit time, per GPU, per researcher, per engineer.</p>
      <p>Genius shifts the distribution. Agent‑accelerated infrastructure increases the number of draws.</p>

      <h3>RL Infra 2026</h3>
      <p>We are <a href="https://ai-2027.com/#narrative-2026-04-30">here</a> in the AI‑2027 narrative. And people still hear “RL infra” and picture train/eval plumbing.</p>
      <p>That’s table stakes.</p>
      <p>What I mean is the system that manufactures effective datapoints with minimal human intervention. I think this is already starting to happen with tools like Codex. For the first time, the tool isn’t just a wrench. It can carry intent across steps.</p>
      <p>Infrastructure used to be like a lathe: rigid, purpose-built, expensive to change. Increasingly it wants to look like an iPhone: a general platform you keep reshaping — by adding apps — as your needs change. And the installation of apps is smoother and smoother.</p>
      <p>If 2025 was about shipping model updates, then 2026 is about making the loop run by itself.</p>
      <p>Some friends in GDM keep saying they’re doing “best‑of‑N.” I want to say: N now includes the agents.</p>

      <details class="appendix">
        <summary>Appendix: Draft Notes (Control-Loop Framing)</summary>

        <h4>The flywheel is a control loop with gain</h4>
        <p>Think of the lab as a closed loop:</p>
        <div class="equation-line">M → A → (τ, q̄) → D<sub>eff</sub> → M</div>
        <ul>
          <li><span class="inline-math">M</span>: model capability (what the model can do)</li>
          <li><span class="inline-math">A</span>: agent capability (how reliably it can execute multi-step work: implement, debug, run experiments, report)</li>
          <li><span class="inline-math">τ</span>: cycle time (idea → experiment → result → attribution → next step)</li>
          <li><span class="inline-math">q̄</span>: average signal quality (how clean/attributable/reproducible each datapoint is)</li>
          <li><span class="inline-math">D<sub>eff</sub></span>: effective datapoints produced per time window</li>
        </ul>

        <h4>What the “gain” product is saying</h4>
        <div class="equation-line">G ≡ (∂M/∂D<sub>eff</sub>) · (∂D<sub>eff</sub>/∂A) · (∂A/∂M)</div>
        <p>This breaks the loop into three sensitivities:</p>
        <ol>
          <li><span class="inline-math">∂A/∂M</span> — <strong>When the model improves, how much does agent capability actually improve?</strong>
            <p>If model gains don’t show up as better tool use, self-debugging, or multi-step reliability, this term stays small. The system gets smarter in evals but not much faster at doing research.</p>
          </li>
          <li><span class="inline-math">∂D<sub>eff</sub>/∂A</span> — <strong>When agents improve, how much does your effective datapoint factory improve?</strong>
            <p>This is the “agents are inside the production line” term. If your infra org doesn’t adopt agents and still requires human bottlenecks everywhere, this term is muted.</p>
          </li>
          <li><span class="inline-math">∂M/∂D<sub>eff</sub></span> — <strong>When you produce more effective datapoints, how much does the next model improve?</strong>
            <p>If datapoints are noisy, non-reproducible, or poorly attributed, scale buys little capability. In the short run (say, 2026), better datapoint quality/attribution probably matters as much as raw quantity.</p>
          </li>
        </ol>
        <p>Multiply them and you get <span class="inline-math">G</span>, the loop’s ability to self-accelerate.</p>
        <ul>
          <li>Small <span class="inline-math">G</span> → incrementalism, flattening, treadmill vibes.</li>
          <li>Large <span class="inline-math">G</span> → compounding: each turn of the loop makes the next turn faster/stronger.</li>
        </ul>
      </details>

    </article>
  </div>
</body>

</html>
